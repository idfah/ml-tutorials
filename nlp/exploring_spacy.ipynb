{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the spaCy NLP library\n",
    "\n",
    "This notebook is a basic, introductory exploration of the spaCy NLP library.  We will explore how to:\n",
    "\n",
    "* download stock models\n",
    "* perform word and sentence tokenization\n",
    "* extract part-of-speech tags\n",
    "* chunk noun phrases\n",
    "* perform named entity recognition\n",
    "\n",
    "This is mostly for my own enlightenment and is not intended to be a thorough tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SpaCy](https://spacy.io/) is an [open-source library](https://github.com/explosion/spaCy) for performing a variety of NLP tasks.  SpaCy claims to be an \"industrial strength\" library aimed at real-world and production NLP use cases.\n",
    "\n",
    "Let's begin by importing the spaCy library and any dependencies we might need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and installing stock models\n",
    "\n",
    "SpaCy comes with a number of stock models, in various languages, that are ready for immediate use.  After browsing through the [online model catelog](https://spacy.io/models), it sounds like we'll be interested in looking at the `en_core_web_sm` model, which is the stock English model, trained over data fetched from the web and with a relatively small footprint.  The model is described by spaCy as an \"English multi-task CNN trained on OntoNotes,\" that \"Assigns context-specific token vectors, POS tags, dependency parse and named entities.\"\n",
    "\n",
    "Note that each model contains multiple pipleine components, i.e., NLP features, packaged together.  The `en_core_web_sm` model, for example, contains tagger, parser and NER components.\n",
    "\n",
    "SpaCy models can be downloaded directly from a shell prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /home/idfah/.local/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/idfah/.local/lib/python3.8/site-packages (from en_core_web_sm==2.3.1) (2.3.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/idfah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/idfah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/idfah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/idfah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/idfah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/idfah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/idfah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/idfah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/idfah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/idfah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/idfah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.50.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /home/idfah/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (41.6.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/idfah/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/idfah/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/idfah/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/idfah/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.6.20)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Keyring is skipped due to an exception: Failed to unlock the keyring!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, the model can be downloaded directly from a python or ipython prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model has been successfully downloaded, it can now be loaded from within python using the `spacy.load` function.\n",
    "\n",
    "Note that we use the variable name `nlp` for the object returned by the model load operation.  This object can be thought of as an \"NLP processing pipeline\" that can be called over text document to apply all of the pipeline components contained in the downloaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample document\n",
    "\n",
    "Next, let's load some sample data to play with.  The document that we will look at is a plaintext version of my PhD dissertation; however, any English document would do here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dissertation.txt', mode='r', encoding='utf8') as fh:\n",
    "    data = fh.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure it was loaded correctly, we print the first 1,500 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISSERTATION\n",
      "\n",
      "CONVOLUTIONAL NEURAL NETWORKS FOR EEG SIGNAL CLASSIFICATION IN\n",
      "ASYNCHRONOUS BRAIN-COMPUTER INTERFACES\n",
      "\n",
      "Submitted by\n",
      "Elliott M. Forney\n",
      "Department of Computer Science\n",
      "\n",
      "In partial fulfillment of the requirements\n",
      "For the Degree of Doctor of Philosophy\n",
      "Colorado State University\n",
      "Fort Collins, Colorado\n",
      "Fall 2019\n",
      "\n",
      "Doctoral Committee:\n",
      "Advisor: Charles Anderson\n",
      "Asa Ben-Hur\n",
      "Michael Kirby\n",
      "Donald Rojas\n",
      "\n",
      "Copyright Elliott M. Forney 2019\n",
      "\n",
      "This work is licensed under the Creative Commons\n",
      "Attribution-NonCommercial-NoDerivatives 4.0 International Public License.\n",
      "\n",
      "You are permitted to share this document without modification for non-commercial purposes.\n",
      "To view a copy of the full license, please see Appendix ??.\n",
      "\n",
      "ABSTRACT\n",
      "\n",
      "CONVOLUTIONAL NEURAL NETWORKS FOR EEG SIGNAL CLASSIFICATION IN\n",
      "ASYNCHRONOUS BRAIN-COMPUTER INTERFACES\n",
      "\n",
      "Brain-Computer Interfaces (BCIs) are emerging technologies that enable users to interact\n",
      "with computerized devices using only voluntary changes in their mental state. BCIs have a\n",
      "number of important applications, especially in the development of assistive technologies for\n",
      "people with motor impairments. Asynchronous BCIs are systems that aim to establish smooth,\n",
      "continuous control of devices like mouse cursors, electric wheelchairs and robotic prostheses\n",
      "without requiring the user to interact with time-locked external stimuli.\n",
      "Scalp-recorded Electroencephalography (EEG) is a noninvasive approach for measuring\n",
      "brain activity that shows considerable potential for \n"
     ]
    }
   ],
   "source": [
    "print(data[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the pipeline\n",
    "\n",
    "Next, we apply the `nlp` pipeline to out text `data` and store the resulting object in the variable `doc`.\n",
    "\n",
    "This takes a bit, so we also track the time taken to apply the pipeline.  On my machine, this takes about eight seconds.  Note that spaCy does have a [GPU-enabled package that can be installed](https://spacy.io/usage#gpu), but we'll stick to the standard version for now and explore computational performance more deeply on another day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.440038204193115"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "doc = nlp(data)\n",
    "\n",
    "time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at tokens\n",
    "\n",
    "Note that the `doc` object is an instance of `spacy.tokens.doc.Doc` and behaves like a sequence of word tokens when iterated over direclty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our document contains about 89,000 words and we can easily access the string representations of these words by iterating over `doc` and accessing the `.text` attribute of the resulting `spacy.tokens.token.Token` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(spacy.tokens.token.Token, 89119)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc[0]), len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows for simple, pythonic expressions to be used to access word tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DISSERTATION',\n",
       " '\\n\\n',\n",
       " 'CONVOLUTIONAL',\n",
       " 'NEURAL',\n",
       " 'NETWORKS',\n",
       " 'FOR',\n",
       " 'EEG',\n",
       " 'SIGNAL',\n",
       " 'CLASSIFICATION',\n",
       " 'IN',\n",
       " '\\n',\n",
       " 'ASYNCHRONOUS',\n",
       " 'BRAIN',\n",
       " '-',\n",
       " 'COMPUTER',\n",
       " 'INTERFACES',\n",
       " '\\n\\n',\n",
       " 'Submitted',\n",
       " 'by',\n",
       " '\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in doc[:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token offsets\n",
    "\n",
    "The character offset of each token within the original text is stored in the `.idx` attribute of each `Token` object.  The begin and end offsets can then be extracted using the starting offset and the length of each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DISSERTATION', 0, 12),\n",
       " ('\\n\\n', 12, 14),\n",
       " ('CONVOLUTIONAL', 14, 27),\n",
       " ('NEURAL', 28, 34),\n",
       " ('NETWORKS', 35, 43),\n",
       " ('FOR', 44, 47),\n",
       " ('EEG', 48, 51),\n",
       " ('SIGNAL', 52, 58),\n",
       " ('CLASSIFICATION', 59, 73),\n",
       " ('IN', 74, 76),\n",
       " ('\\n', 76, 77),\n",
       " ('ASYNCHRONOUS', 77, 89),\n",
       " ('BRAIN', 90, 95),\n",
       " ('-', 95, 96),\n",
       " ('COMPUTER', 96, 104),\n",
       " ('INTERFACES', 105, 115),\n",
       " ('\\n\\n', 115, 117),\n",
       " ('Submitted', 117, 126),\n",
       " ('by', 127, 129),\n",
       " ('\\n', 129, 130)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token.text, token.idx, token.idx + len(token)) for token in doc[:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be confirmed by extracting each token from the original document using only the token offsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DISSERTATION',\n",
       " '\\n\\n',\n",
       " 'CONVOLUTIONAL',\n",
       " 'NEURAL',\n",
       " 'NETWORKS',\n",
       " 'FOR',\n",
       " 'EEG',\n",
       " 'SIGNAL',\n",
       " 'CLASSIFICATION',\n",
       " 'IN',\n",
       " '\\n',\n",
       " 'ASYNCHRONOUS',\n",
       " 'BRAIN',\n",
       " '-',\n",
       " 'COMPUTER',\n",
       " 'INTERFACES',\n",
       " '\\n\\n',\n",
       " 'Submitted',\n",
       " 'by',\n",
       " '\\n']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[data[token.idx:token.idx + len(token)] for token in doc[:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting part-of-speech tags\n",
    "\n",
    "The predicted Part-Of-Speech (POS) tags can be access using the `.pos_` attribute on each `Token` object.\n",
    "\n",
    "Note that the `.pos_` attribute returns the string representation of the POS tag from the [Universal POS Tag Set](https://universaldependencies.org/docs/u/pos/) while the `.pos` attribute is an integer enum-style representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOUN',\n",
       " 'SPACE',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'PROPN',\n",
       " 'PROPN',\n",
       " 'VERB',\n",
       " 'ADP',\n",
       " 'SPACE',\n",
       " 'PROPN',\n",
       " 'PROPN',\n",
       " 'PUNCT',\n",
       " 'NOUN',\n",
       " 'PROPN',\n",
       " 'SPACE',\n",
       " 'VERB',\n",
       " 'ADP',\n",
       " 'SPACE']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.pos_ for token in doc[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[92,\n",
       " 103,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 85,\n",
       " 96,\n",
       " 96,\n",
       " 100,\n",
       " 85,\n",
       " 103,\n",
       " 96,\n",
       " 96,\n",
       " 97,\n",
       " 92,\n",
       " 96,\n",
       " 103,\n",
       " 100,\n",
       " 85,\n",
       " 103]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.pos for token in doc[:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is straightforward to get tuples containing both the token text along side the corresponding POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(DISSERTATION, 'NOUN'),\n",
       " (\n",
       "  , 'SPACE'),\n",
       " (CONVOLUTIONAL, 'NOUN'),\n",
       " (NEURAL, 'NOUN'),\n",
       " (NETWORKS, 'NOUN'),\n",
       " (FOR, 'ADP'),\n",
       " (EEG, 'PROPN'),\n",
       " (SIGNAL, 'PROPN'),\n",
       " (CLASSIFICATION, 'VERB'),\n",
       " (IN, 'ADP'),\n",
       " (, 'SPACE'),\n",
       " (ASYNCHRONOUS, 'PROPN'),\n",
       " (BRAIN, 'PROPN'),\n",
       " (-, 'PUNCT'),\n",
       " (COMPUTER, 'NOUN'),\n",
       " (INTERFACES, 'PROPN'),\n",
       " (\n",
       "  ,\n",
       "  'SPACE'),\n",
       " (Submitted, 'VERB'),\n",
       " (by, 'ADP'),\n",
       " (, 'SPACE')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token, token.pos_) for token in doc[:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token \"is\" and \"like\" attributes\n",
    "\n",
    "Each token also has convenient attributes that denote whether or not it looks like a digit, number, email, et cetra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_2019 = doc[54]\n",
    "word_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2019, True, True, False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_2019, word_2019.is_digit, word_2019.like_num, word_2019.like_email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER)\n",
    "\n",
    "Our pipeline also contained a component for performing NER.  While iterating over the `doc` variable directly operates over tokens, the results from additional pipeline components are generally `Span` object, which represent a series of contiguous tokens, as an attribute that is placed onto the `doc` object.\n",
    "\n",
    "In this case, we have an attribute called `doc.ents` that is a tuple of `Span` objects representing each entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, spacy.tokens.span.Span)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc.ents), type(doc.ents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, pythonic expressions, e.g., list comprehensions, can be used to extract information from this tuple of `Span`'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[INTERFACES,\n",
       " Elliott M. Forney,\n",
       " Department of Computer Science,\n",
       " the Degree of Doctor of Philosophy,\n",
       " Colorado State University,\n",
       " Fort Collins,\n",
       " Colorado,\n",
       " Fall 2019,\n",
       " Doctoral Committee,\n",
       " Charles Anderson,\n",
       " Asa Ben-Hur,\n",
       " Michael Kirby,\n",
       " Donald Rojas,\n",
       " the Creative Commons,\n",
       " NonCommercial-NoDerivatives,\n",
       " Appendix,\n",
       " EEG,\n",
       " EEG,\n",
       " the Convolutional Neural Network,\n",
       " CNN]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ent for ent in doc.ents[:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.label_` attribute contains a string version of the predicted entity type while `.label` attribute holds an integer representation, similar to what we saw for POS tags.\n",
    "\n",
    "Note that entities are not disambiguated, merged or linked.  *It's unclear to me if there is any way to do these things in spaCy?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('INTERFACES', 'ORG', 383),\n",
       " ('Elliott M. Forney\\n', 'PERSON', 380),\n",
       " ('Department of Computer Science', 'ORG', 383),\n",
       " ('the Degree of Doctor of Philosophy\\n', 'WORK_OF_ART', 388),\n",
       " ('Colorado State University', 'ORG', 383),\n",
       " ('Fort Collins', 'GPE', 384),\n",
       " ('Colorado', 'GPE', 384),\n",
       " ('Fall 2019', 'DATE', 391),\n",
       " ('Doctoral Committee', 'ORG', 383),\n",
       " ('Charles Anderson', 'PERSON', 380),\n",
       " ('Asa Ben-Hur', 'PERSON', 380),\n",
       " ('Michael Kirby', 'PERSON', 380),\n",
       " ('Donald Rojas', 'PERSON', 380),\n",
       " ('the Creative Commons', 'ORG', 383),\n",
       " ('NonCommercial-NoDerivatives', 'ORG', 383),\n",
       " ('Appendix', 'GPE', 384),\n",
       " ('EEG', 'ORG', 383),\n",
       " ('EEG', 'ORG', 383),\n",
       " ('the Convolutional Neural Network', 'ORG', 383),\n",
       " ('CNN', 'ORG', 383)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(ent.text, ent.label_, ent.label) for ent in doc.ents[:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, pythonic expressions can be used to do things like extract the text for all entities of a given type.\n",
    "\n",
    "`PERSON` entities look pretty good..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elliott M. Forney\\n',\n",
       " 'Charles Anderson',\n",
       " 'Asa Ben-Hur',\n",
       " 'Michael Kirby',\n",
       " 'Donald Rojas',\n",
       " 'Charles Anderson',\n",
       " 'BCI',\n",
       " 'Bill Gavin',\n",
       " 'Marla Roll',\n",
       " 'Brittany Taylor',\n",
       " 'Jewel Crasta',\n",
       " 'Stephanie Scott',\n",
       " 'Katie Bruegger',\n",
       " 'Kim Teh',\n",
       " 'Stephanie Teh',\n",
       " 'Tomojit Ghosh',\n",
       " 'Glen Forney',\n",
       " 'Nancy Forney',\n",
       " 'Maggie',\n",
       " 'Parker']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ent.text for ent in doc.ents if ent.label_ == 'PERSON'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ORG` has some misses, especially with abbreviations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INTERFACES',\n",
       " 'Department of Computer Science',\n",
       " 'Colorado State University',\n",
       " 'Doctoral Committee',\n",
       " 'the Creative Commons',\n",
       " 'NonCommercial-NoDerivatives',\n",
       " 'EEG',\n",
       " 'EEG',\n",
       " 'the Convolutional Neural Network',\n",
       " 'CNN',\n",
       " 'EEG',\n",
       " 'Time-Delay Neural',\n",
       " 'EEG',\n",
       " 'EEG',\n",
       " 'Fourier',\n",
       " 'EEG',\n",
       " 'EEG',\n",
       " 'CSU',\n",
       " 'Patti Davies',\n",
       " 'EEG']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ent.text for ent in doc.ents if ent.label_ == 'ORG'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for `GPE` (geopolitical entities)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fort Collins',\n",
       " 'Colorado',\n",
       " 'Appendix',\n",
       " 'Colorado',\n",
       " 'distinct mental states',\n",
       " 's2',\n",
       " 'sT',\n",
       " 'DFT',\n",
       " 'Sa\\n\\n',\n",
       " 'noisy',\n",
       " 'CSP-2',\n",
       " 'MI',\n",
       " 'al.',\n",
       " 'al.',\n",
       " '−',\n",
       " '−',\n",
       " 'Mn',\n",
       " 'i.e',\n",
       " 'Unnikrishnan',\n",
       " 'Tzanakou']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ent.text for ent in doc.ents if ent.label_ == 'GPE'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun-phrase chunking\n",
    "\n",
    "Noun chunks are also extracted by our pipeline.  This time, however, we are given a generator instead of list, which is certainly reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc.noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(spacy.tokens.span.Span, 17531)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_chunks = list(doc.noun_chunks)\n",
    "\n",
    "type(noun_chunks[0]), len(noun_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, noun chunks are easily extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DISSERTATION',\n",
       " 'CONVOLUTIONAL NEURAL NETWORKS',\n",
       " 'EEG SIGNAL',\n",
       " 'ASYNCHRONOUS BRAIN-COMPUTER INTERFACES',\n",
       " 'Elliott M. Forney',\n",
       " 'Department',\n",
       " 'Computer Science',\n",
       " 'partial fulfillment',\n",
       " 'the requirements',\n",
       " 'the Degree',\n",
       " 'Doctor',\n",
       " 'Philosophy',\n",
       " 'Colorado State University',\n",
       " 'Fort Collins',\n",
       " 'Colorado',\n",
       " 'Fall',\n",
       " 'Doctoral Committee',\n",
       " 'Advisor',\n",
       " 'Charles Anderson',\n",
       " 'Asa Ben-Hur',\n",
       " 'Michael Kirby',\n",
       " 'Donald Rojas',\n",
       " 'Copyright Elliott M. Forney',\n",
       " 'This work',\n",
       " 'the Creative Commons\\nAttribution-NonCommercial-NoDerivatives 4.0 International Public License',\n",
       " 'You',\n",
       " 'this document',\n",
       " 'modification',\n",
       " 'non-commercial purposes',\n",
       " 'a copy',\n",
       " 'the full license',\n",
       " 'Appendix',\n",
       " 'ABSTRACT\\n\\nCONVOLUTIONAL NEURAL NETWORKS',\n",
       " 'EEG SIGNAL',\n",
       " 'ASYNCHRONOUS BRAIN-COMPUTER INTERFACES',\n",
       " 'Brain-Computer Interfaces',\n",
       " 'BCIs',\n",
       " 'technologies',\n",
       " 'users',\n",
       " 'computerized devices',\n",
       " 'only voluntary changes',\n",
       " 'their mental state',\n",
       " 'BCIs',\n",
       " 'a\\nnumber',\n",
       " 'important applications',\n",
       " 'the development',\n",
       " 'assistive technologies',\n",
       " 'people',\n",
       " 'motor impairments',\n",
       " 'Asynchronous BCIs',\n",
       " 'systems',\n",
       " 'continuous control',\n",
       " 'devices',\n",
       " 'mouse cursors',\n",
       " 'electric wheelchairs and robotic prostheses',\n",
       " 'the user',\n",
       " 'time-locked external stimuli',\n",
       " 'Scalp-recorded Electroencephalography',\n",
       " '(EEG',\n",
       " 'a noninvasive approach',\n",
       " 'brain activity',\n",
       " 'considerable potential',\n",
       " 'use',\n",
       " 'BCIs',\n",
       " 'a user',\n",
       " 'spontaneously produced EEG signals',\n",
       " 'a challenging problem',\n",
       " 'specialized machine learning and signal processing methods',\n",
       " 'Current approaches',\n",
       " 'guided preprocessing',\n",
       " 'feature generation procedures',\n",
       " 'combination',\n",
       " 'classification algorithms',\n",
       " 'The current trend',\n",
       " 'machine learning',\n",
       " 'approaches',\n",
       " 'feature engineering',\n",
       " 'favor',\n",
       " 'multilayer (deep) artificial neural networks',\n",
       " 'few prior assumptions',\n",
       " 'hierarchical, multiscale representations',\n",
       " 'these lines',\n",
       " 'we',\n",
       " 'several variants',\n",
       " 'the Convolutional Neural Network',\n",
       " '(CNN',\n",
       " 'architecture',\n",
       " 'EEG signals',\n",
       " 'asynchronous BCIs',\n",
       " 'These networks',\n",
       " 'convolutions',\n",
       " 'time',\n",
       " 'dense connectivity',\n",
       " 'channels',\n",
       " 'them',\n",
       " 'spatiotemporal patterns',\n",
       " 'time invariance',\n",
       " 'Class\\nlabels',\n",
       " 'linear readout layers',\n",
       " 'label aggregation',\n",
       " 'order',\n",
       " 'susceptibility',\n",
       " 'overfitting',\n",
       " 'continuous control',\n",
       " 'We',\n",
       " 'transfer',\n",
       " 'order',\n",
       " 'overfitting',\n",
       " 'leverage patterns',\n",
       " 'individuals',\n",
       " 'We',\n",
       " 'these networks',\n",
       " 'multilayer generalizations',\n",
       " 'Time-Delay Neural',\n",
       " 'Networks',\n",
       " 'TDNNs',\n",
       " 'the convolutional units',\n",
       " 'these networks',\n",
       " 'learned, multivariate, nonlinear, finite impulse-response filters',\n",
       " 'We',\n",
       " 'a series',\n",
       " 'offline experiments',\n",
       " 'EEG data',\n",
       " 'four imagined\\nmental tasks',\n",
       " 'a left-handed fist',\n",
       " 'a rotating cube',\n",
       " 'a favorite song',\n",
       " 'Data',\n",
       " 'a portable,\\neight-channel EEG system',\n",
       " '10 participants',\n",
       " 'no impairments',\n",
       " 'a laboratory setting',\n",
       " 'four participants',\n",
       " 'motor impairments',\n",
       " 'their home environments',\n",
       " 'Experimental\\nresults',\n",
       " 'our proposed CNNs',\n",
       " 'baseline classifiers',\n",
       " 'power-spectral densities',\n",
       " 'Transfer learning',\n",
       " 'an additional performance',\n",
       " 'improvement',\n",
       " 'combination',\n",
       " 'multilayer networks',\n",
       " 'Our final test',\n",
       " 'results',\n",
       " 'a mean classification accuracy',\n",
       " '57.86%',\n",
       " 'the\\n49.29%',\n",
       " 'our baseline classifiers',\n",
       " 'terms',\n",
       " 'information transfer rates',\n",
       " 'our\\nproposed methods',\n",
       " 'a mean',\n",
       " '15.82 bits',\n",
       " 'minute',\n",
       " 'our baseline methods',\n",
       " '9.35 bits',\n",
       " 'minute',\n",
       " 'two individuals',\n",
       " 'our CNNs',\n",
       " 'a classification accuracy',\n",
       " '90.00%',\n",
       " 'our baseline methods',\n",
       " 'A comparison',\n",
       " 'external\\nstudies',\n",
       " 'these results',\n",
       " 'par',\n",
       " 'the state',\n",
       " 'the-art',\n",
       " 'our relatively\\nrigorous experimental design',\n",
       " 'We',\n",
       " 'a number',\n",
       " 'experiments',\n",
       " 'the types',\n",
       " 'patterns',\n",
       " 'our classifiers',\n",
       " 'a detailed analysis',\n",
       " 'aggregate power-spectral densities',\n",
       " 'the layer',\n",
       " 'wise activations',\n",
       " 'our CNNs',\n",
       " 'the frequency',\n",
       " 'responses',\n",
       " 'convolutional layers',\n",
       " 'Fourier analysis',\n",
       " 'optimized input',\n",
       " 'sequences',\n",
       " 'trained networks',\n",
       " 'These analyses',\n",
       " 'several ways',\n",
       " 'the patterns',\n",
       " 'our\\nmethods',\n",
       " 'known patterns',\n",
       " 'EEG signals',\n",
       " 'new questions',\n",
       " 'some types',\n",
       " 'patterns',\n",
       " 'high-frequency information',\n",
       " 'the behavior',\n",
       " 'our CNNs',\n",
       " 'insights',\n",
       " 'the inner workings',\n",
       " 'these\\n\\nnetworks',\n",
       " 'they',\n",
       " 'fact',\n",
       " 'hierarchical, multiscale\\nrepresentations',\n",
       " 'EEG signals',\n",
       " 'I',\n",
       " 'Charles Anderson',\n",
       " 'the teaching',\n",
       " 'mentorship',\n",
       " 'guidance',\n",
       " 'he',\n",
       " 'me',\n",
       " 'the years',\n",
       " 'his feedback',\n",
       " 'comments',\n",
       " 'proofreading',\n",
       " 'this\\ndocument',\n",
       " 'the code',\n",
       " 'I',\n",
       " 'my implementations',\n",
       " 'his courses',\n",
       " 'machine learning',\n",
       " 'his contributions',\n",
       " 'the CEBL3 project',\n",
       " 'I',\n",
       " 'the wonderful and inspirational teachers',\n",
       " 'CSU',\n",
       " 'I',\n",
       " 'you',\n",
       " 'I',\n",
       " 'my dissertation committee',\n",
       " 'the members',\n",
       " 'the BCI laboratory',\n",
       " 'Bill Gavin',\n",
       " 'Patti Davies',\n",
       " 'Marla Roll',\n",
       " 'me',\n",
       " 'what',\n",
       " 'I',\n",
       " 'EEG',\n",
       " 'participants',\n",
       " 'a kind and professional way',\n",
       " 'Brittany Taylor',\n",
       " 'Jewel Crasta',\n",
       " 'Stephanie Scott',\n",
       " 'Katie Bruegger',\n",
       " 'Kim Teh',\n",
       " 'Stephanie Teh',\n",
       " 'the success',\n",
       " 'my research',\n",
       " 'the BCI project',\n",
       " 'great sources',\n",
       " 'support',\n",
       " 'friendship',\n",
       " 'Tomojit Ghosh',\n",
       " 'Fereydoon Vafaei',\n",
       " 'great friends',\n",
       " 'colleagues',\n",
       " 'the process',\n",
       " 'formulating',\n",
       " 'my ideas',\n",
       " 'my experiments',\n",
       " 'I',\n",
       " 'you',\n",
       " 'everyone',\n",
       " 'our studies',\n",
       " 'who',\n",
       " 'us',\n",
       " 'their homes',\n",
       " 'I',\n",
       " 'this research',\n",
       " 'next-generation\\nassistive technologies',\n",
       " 'everyone',\n",
       " 'who',\n",
       " 'them',\n",
       " 'This work',\n",
       " 'part',\n",
       " 'the National Science Foundation',\n",
       " 'grant number',\n",
       " 'generous support',\n",
       " 'the Department',\n",
       " 'Computer Science',\n",
       " 'Department',\n",
       " 'Occupational',\n",
       " 'Therapy',\n",
       " 'Department',\n",
       " 'Human Development',\n",
       " 'Family Studies',\n",
       " 'Colorado State',\n",
       " 'University',\n",
       " 'I',\n",
       " 'generous financial support',\n",
       " 'the Forney Family Scholarship',\n",
       " 'the Computer Science Department',\n",
       " 'Artificial Intelligence',\n",
       " 'Evolutionary',\n",
       " 'Computation Fellowship',\n",
       " 'I',\n",
       " 'my father',\n",
       " 'Glen Forney',\n",
       " 'my passion',\n",
       " 'science',\n",
       " 'my mother',\n",
       " 'Nancy Forney',\n",
       " 'her passion',\n",
       " 'reading',\n",
       " 'writing',\n",
       " 'critical thinking',\n",
       " 'I',\n",
       " 'my wife',\n",
       " 'Maggie',\n",
       " 'my two children',\n",
       " 'Parker',\n",
       " 'Alexa',\n",
       " 'their phenomenal and enduring support',\n",
       " 'my academic endeavors',\n",
       " 'TABLE',\n",
       " 'CONTENTS',\n",
       " 'ABSTRACT',\n",
       " 'ACKNOWLEDGEMENTS',\n",
       " 'LIST',\n",
       " 'TABLES',\n",
       " 'LIST',\n",
       " 'FIGURES',\n",
       " 'viii',\n",
       " 'Chapter',\n",
       " 'Introduction',\n",
       " 'Challenges',\n",
       " 'Problem Statement',\n",
       " 'Proposed Solution',\n",
       " 'Outline',\n",
       " 'Remaining Chapters',\n",
       " 'Chapter',\n",
       " 'Background',\n",
       " 'Current Approaches',\n",
       " 'Power Spectral Densities',\n",
       " 'Common Spatial Patterns',\n",
       " 'Time-Delay Embedding',\n",
       " 'Deep Learning',\n",
       " 'Convolutional Neural Networks',\n",
       " 'CNNs',\n",
       " 'Computer Vision',\n",
       " 'CNNs',\n",
       " 'Brain-Computer Interfaces',\n",
       " 'Transfer Learning',\n",
       " 'Chapter',\n",
       " 'Methods',\n",
       " '. . . . . . . . . . . . . . . . . . . . . . . . . .\\nBaseline Classifiers',\n",
       " 'Discriminant Analysis',\n",
       " 'Artificial Neural Networks',\n",
       " '. . . . . . . . . . . . . .\\nTime-Delay Neural Networks',\n",
       " 'Label Aggregation',\n",
       " 'Time-Delay Embedding',\n",
       " 'a Discrete Convolution',\n",
       " 'Finite Impulse-Response Filters',\n",
       " 'Deep Convolutional Networks',\n",
       " 'Fully Connected Readout Layers',\n",
       " 'Label Aggregation Readout Layers',\n",
       " 'Transfer Learning',\n",
       " 'Input Sequences',\n",
       " 'Neural Network Details',\n",
       " 'Initialization and Transfer Function',\n",
       " 'Pooling',\n",
       " 'Scaled Conjugate Gradients',\n",
       " 'Regularization',\n",
       " '3.5.4\\n\\nData',\n",
       " 'Implementation',\n",
       " 'The Colorado EEG',\n",
       " 'BCI Laboratory Software',\n",
       " 'EEG Acquisition System',\n",
       " 'Participants',\n",
       " 'Mental Tasks',\n",
       " 'Validation and Performance Evaluation',\n",
       " 'Chapter',\n",
       " '4.3.5\\n\\nResults',\n",
       " 'Model Selection',\n",
       " 'Power Spectral Densities',\n",
       " '. . . . .\\nTime-Delay Embedding Networks',\n",
       " 'Convolutional Networks',\n",
       " 'Label Aggregation',\n",
       " 'Transfer Learning',\n",
       " 'Test Performance',\n",
       " 'Power Spectral Densities',\n",
       " 'Convolutional Networks',\n",
       " 'Comparison',\n",
       " 'External Studies',\n",
       " 'the Decision Rate',\n",
       " 'Mental Tasks',\n",
       " 'Analysis',\n",
       " 'Aggregate PSDs',\n",
       " 'LDA Weight Analysis',\n",
       " 'Learned',\n",
       " 'Filters',\n",
       " 'Layerwise Outputs',\n",
       " 'Optimized Input Sequences',\n",
       " 'Chapter',\n",
       " '5.2\\n\\nConclusions',\n",
       " 'Discussion',\n",
       " 'Summary',\n",
       " 'Bibliography',\n",
       " '210\\n\\nLIST',\n",
       " 'TABLES',\n",
       " '3.4\\n\\nSummary',\n",
       " 'PSD baseline classifiers',\n",
       " 'Summary',\n",
       " 'CNN architectures',\n",
       " 'Specifications',\n",
       " 'our EEG acquisition system',\n",
       " 'Mental tasks',\n",
       " 'cues',\n",
       " 'the participants',\n",
       " '4.4\\n4.5\\n\\nNetwork configurations',\n",
       " 'transfer learning experiments',\n",
       " 'Test classification accuracies',\n",
       " 'our baseline classifiers',\n",
       " 'Test classification accuracies',\n",
       " 'our proposed classifiers',\n",
       " 'Test',\n",
       " 'information transfer rates',\n",
       " 'our proposed classifiers',\n",
       " 'LDA',\n",
       " 'CNN-TR',\n",
       " 'FIGURES',\n",
       " 'A subject',\n",
       " 'BCI experiments',\n",
       " 'EEG electrodes',\n",
       " 'the 10/20 standard',\n",
       " 'A sample trace plot',\n",
       " 'a 10-second EEG segment',\n",
       " 'The basic components',\n",
       " 'flow',\n",
       " 'information',\n",
       " 'a BCI',\n",
       " 'A sample',\n",
       " 'a raw PSD',\n",
       " 'A sample',\n",
       " 'a PSD',\n",
       " 'Welch',\n",
       " 'A schematic',\n",
       " 'Welch',\n",
       " 'PSDs',\n",
       " 'PSDs',\n",
       " 'differences',\n",
       " 'phase',\n",
       " 'channels',\n",
       " 'PSDs',\n",
       " 'a limited ability',\n",
       " 'the ordering',\n",
       " 'events',\n",
       " 'PSDs',\n",
       " 'counter-intuitive results',\n",
       " 'signals',\n",
       " 'pure sinusoids',\n",
       " 'CSP',\n",
       " 'the signal variances',\n",
       " 'two narrow-band signals',\n",
       " 'CSP',\n",
       " 'the variances',\n",
       " 'sinusoids',\n",
       " 'different frequencies',\n",
       " 'a CNN',\n",
       " 'image classification',\n",
       " 'A two-layer ANN',\n",
       " 'PSDs',\n",
       " 'A schematic diagram',\n",
       " 'our proposed TDNN architecture',\n",
       " 'A schematic diagram',\n",
       " 'our proposed CNN-FC architecture',\n",
       " 'A schematic diagram',\n",
       " 'our proposed CNN-LA architecture',\n",
       " 'The application',\n",
       " 'our sigmoidal transfer function',\n",
       " 'sine waves',\n",
       " 'The effect',\n",
       " 'impulse response and memory capacity',\n",
       " 'Steepest descent',\n",
       " 'scaled conjugate gradients',\n",
       " 'a quadratic function',\n",
       " 'Layout',\n",
       " 'software modules',\n",
       " 'CEBL3',\n",
       " 'A screen capture',\n",
       " 'the CEBL3 graphical user interface',\n",
       " 'A screencapture',\n",
       " 'our visual cue',\n",
       " 'a user',\n",
       " 'a mental task',\n",
       " 'Validation CA',\n",
       " 'span',\n",
       " 'all PSD classifiers',\n",
       " 'Validation CA',\n",
       " 'regularization parameters',\n",
       " 'LDA',\n",
       " 'QDA',\n",
       " 'Validation CA',\n",
       " 'training',\n",
       " 'iterations',\n",
       " 'an ANN',\n",
       " 'Validation CA',\n",
       " 'hidden units',\n",
       " 'dimension',\n",
       " 'TDNNs',\n",
       " 'Validation CA',\n",
       " 'training',\n",
       " 'iterations',\n",
       " 'a TDNN',\n",
       " 'Validation CA',\n",
       " 'number',\n",
       " 'layers',\n",
       " 'CNN-FCs',\n",
       " 'pooling',\n",
       " 'Weights',\n",
       " 'training',\n",
       " 'iterations',\n",
       " 'a CNN-FC',\n",
       " 'Validation CA',\n",
       " 'training',\n",
       " 'iterations',\n",
       " 'a CNN-FC',\n",
       " 'Validation CA',\n",
       " 'number',\n",
       " 'layers',\n",
       " 'CNN-FCs',\n",
       " 'pooling',\n",
       " 'training',\n",
       " 'iterations',\n",
       " 'a CNN-FC',\n",
       " 'pooling',\n",
       " 'Validation CA',\n",
       " 'training',\n",
       " 'iterations',\n",
       " 'a CNN-FC',\n",
       " 'pooling',\n",
       " 'Validation CA',\n",
       " 'number',\n",
       " 'layers',\n",
       " 'a CNN-LAs',\n",
       " 'Validation CA',\n",
       " 'number',\n",
       " 'layers',\n",
       " 'CNN-LAs',\n",
       " 'pooling',\n",
       " 'training',\n",
       " 'iterations',\n",
       " 'a CNN-LA',\n",
       " 'pooling',\n",
       " 'Validation CA',\n",
       " 'training',\n",
       " 'iterations',\n",
       " 'a CNN-LA',\n",
       " 'pooling',\n",
       " 'Validation CA',\n",
       " 'initial training iterations',\n",
       " 'CNN-TRs',\n",
       " '4.33\\n\\nValidation CA',\n",
       " 'training',\n",
       " 'iterations',\n",
       " 'a CNN-TR',\n",
       " 'Distribution',\n",
       " 'test CAs',\n",
       " 'our baseline classifiers',\n",
       " 'Distribution',\n",
       " 'test CAs',\n",
       " 'our proposed classifiers',\n",
       " 'segment length',\n",
       " 'Boxplots',\n",
       " 'task',\n",
       " 'all subjects',\n",
       " 'Average PSDs',\n",
       " 'all tasks',\n",
       " 'each subject',\n",
       " 'Average PSDs',\n",
       " 'Mental Task',\n",
       " 'PSD features',\n",
       " 'LDA weights',\n",
       " 'Subject',\n",
       " 'PSD features',\n",
       " 'LDA weights',\n",
       " 'Subject',\n",
       " 'the FIR filters',\n",
       " 'a TDNN',\n",
       " 'the FIR filters',\n",
       " 'a TDNN',\n",
       " 'Best-performing EEG segments',\n",
       " 'our small CNN-TR',\n",
       " 'Layer-wise activations',\n",
       " 'a small CNN-TR',\n",
       " 'Predicted class probabilities',\n",
       " 'ALOPEX iterations',\n",
       " 'Optimized and actual input segments',\n",
       " 'each task',\n",
       " 'our small CNN-TR',\n",
       " 'PSDs',\n",
       " 'the actual and optimized input segments',\n",
       " 'our small CNN-TR',\n",
       " '.\\nLayer-wise activations',\n",
       " 'our small CNN-TR',\n",
       " 'optimized input segments',\n",
       " 'Chapter',\n",
       " 'Introduction',\n",
       " 'Brain-computer Interfaces',\n",
       " 'BCIs',\n",
       " 'systems',\n",
       " 'a direct channel',\n",
       " 'communication',\n",
       " 'the human brain',\n",
       " 'a computerized device',\n",
       " 'many potential applications',\n",
       " 'BCI systems',\n",
       " 'the development',\n",
       " 'assistive technologies',\n",
       " 'people',\n",
       " 'motor impairments',\n",
       " 'a goal',\n",
       " 'the near future',\n",
       " 'significant benefits',\n",
       " 'individuals',\n",
       " 'society',\n",
       " 'people',\n",
       " 'disabilities',\n",
       " 'assistive devices',\n",
       " 'BCIs',\n",
       " 'the potential',\n",
       " 'their ability',\n",
       " 'daily tasks',\n",
       " 'people',\n",
       " 'severe impairments',\n",
       " 'even BCIs',\n",
       " 'slow\\ncommunication rates',\n",
       " 'who',\n",
       " 'all or nearly all voluntary\\nmotor function',\n",
       " 'a condition',\n",
       " 'locked-in syndrome',\n",
       " 'BCIs',\n",
       " 'their only means',\n",
       " 'communication',\n",
       " 'the outside world',\n",
       " 'A number',\n",
       " 'methods',\n",
       " 'changes',\n",
       " 'brain activity',\n",
       " 'use',\n",
       " 'BCIs',\n",
       " 'functional nuclear Magnetic Resonance Imaging',\n",
       " 'fMRI',\n",
       " 'microarrays',\n",
       " 'brain tissue',\n",
       " '8–11',\n",
       " 'these approaches',\n",
       " 'scalp-recorded Electroencephalography',\n",
       " '(EEG',\n",
       " 'a popular choice',\n",
       " 'EEG measures',\n",
       " 'electrical potentials',\n",
       " 'the surface',\n",
       " 'the scalp',\n",
       " 'the synchronized firing',\n",
       " 'action',\n",
       " 'potentials',\n",
       " 'neurons',\n",
       " 'the cortical surface',\n",
       " 'the brain',\n",
       " 'EEG',\n",
       " 'surgical intervention',\n",
       " 'it',\n",
       " 'people',\n",
       " 'motor impairments',\n",
       " 'Modern EEG equipment',\n",
       " 'it',\n",
       " 'use',\n",
       " 'a variety',\n",
       " 'assistive devices',\n",
       " 'EEG',\n",
       " 'a high\\ntemporal resolution',\n",
       " 'the order',\n",
       " 'microseconds',\n",
       " 'it',\n",
       " 'use',\n",
       " 'real-time applications',\n",
       " 'Figure',\n",
       " 'we',\n",
       " 'an image',\n",
       " 'the participants',\n",
       " 'our study',\n",
       " 'who',\n",
       " 'quadriplegia',\n",
       " 'an eight-channel EEG cap',\n",
       " 'BCI experiments',\n",
       " 'his work',\n",
       " 'environment',\n",
       " 'a small amount',\n",
       " 'electrically conductive gel',\n",
       " 'colin_cropped_bright.jpg',\n",
       " 'Figure',\n",
       " 'A participant',\n",
       " 'quadriplegia',\n",
       " 'an eight-channel EEG cap',\n",
       " 'BCI experiments',\n",
       " 'their office',\n",
       " '/chan_diagram.pdf\\n\\nFigure',\n",
       " 'The layout',\n",
       " 'naming',\n",
       " 'convention',\n",
       " 'EEG electrode placement',\n",
       " 'the 10/20 standard',\n",
       " 'Our portable\\nEEG system',\n",
       " 'the eight highlighted channels',\n",
       " 'Figure',\n",
       " 'A sample trace plot',\n",
       " 'a 10-second EEG segment',\n",
       " 'The vertical axis',\n",
       " 'signal voltage',\n",
       " 'µV',\n",
       " 'the eight channels',\n",
       " 'the horizontal axis',\n",
       " 'time',\n",
       " 'order',\n",
       " 'the impedance',\n",
       " 'the sensors',\n",
       " 'the scalp',\n",
       " 'Figure',\n",
       " 'we',\n",
       " 'the layout',\n",
       " 'convention',\n",
       " 'EEG electrode placement',\n",
       " 'the 10/20\\nstandard',\n",
       " 'The first letter',\n",
       " 'each site name',\n",
       " 'a region',\n",
       " 'the brain',\n",
       " 'Frontal',\n",
       " 'The numbers',\n",
       " 'the sites',\n",
       " 'odd\\nnumbers',\n",
       " 'the left hemisphere',\n",
       " 'the brain',\n",
       " 'even numbers',\n",
       " 'we',\n",
       " 'Section',\n",
       " 'our EEG system',\n",
       " 'a portable eight-channel\\nsystem',\n",
       " 'the eight sites',\n",
       " 'Figure',\n",
       " 'Figure',\n",
       " 'we',\n",
       " 'a sample',\n",
       " 'trace plot',\n",
       " 'a 10-second EEG segment',\n",
       " 'The vertical axis',\n",
       " 'the signal voltage',\n",
       " 'channel',\n",
       " 'the horizontal axis',\n",
       " 'time',\n",
       " 'EEG',\n",
       " 'a number',\n",
       " 'properties',\n",
       " 'it',\n",
       " 'use',\n",
       " 'BCIs',\n",
       " 'it',\n",
       " 'a number',\n",
       " 'significant challenges',\n",
       " 'EEG signals',\n",
       " 'the various layers',\n",
       " 'meninges',\n",
       " 'skull',\n",
       " 'scalp',\n",
       " 'they',\n",
       " 'activity',\n",
       " 'the cortical surface',\n",
       " 'the brain',\n",
       " 'a\\npartial and imprecise representation',\n",
       " 'the underlying neural activity',\n",
       " 'EEG signals',\n",
       " 'small magnitudes',\n",
       " 'the order',\n",
       " 'microvolts',\n",
       " 'noise',\n",
       " 'external sources',\n",
       " 'computer peripherals',\n",
       " 'household appliances',\n",
       " 'power mains',\n",
       " 'It',\n",
       " 'EEG signals',\n",
       " 'artifacts',\n",
       " 'biological sources',\n",
       " 'ocular\\nmovements',\n",
       " 'muscle contractions',\n",
       " 'cardiac rhythms',\n",
       " 'Noise',\n",
       " 'artifacts',\n",
       " 'real-world environments',\n",
       " 'BCI systems',\n",
       " 'The sheer complexity',\n",
       " 'the human brain',\n",
       " 'EEG signals',\n",
       " 'sophisticated spatiotemporal patterns',\n",
       " 'a problem',\n",
       " 'the fact',\n",
       " 'the brain',\n",
       " 'multiple tasks',\n",
       " 'parallel',\n",
       " 'these challenges',\n",
       " 'a number',\n",
       " 'research groups',\n",
       " 'EEG-based BCI systems',\n",
       " 'Several software packages',\n",
       " 'BCI experiments',\n",
       " 'several companies',\n",
       " 'commercial BCI\\nproducts',\n",
       " 'recent years',\n",
       " 'several people',\n",
       " 'who',\n",
       " 'Amyotrophic Lateral Sclerosis',\n",
       " 'ALS',\n",
       " 'BCI systems',\n",
       " 'communication',\n",
       " 'a daily basis',\n",
       " 'Some research groups',\n",
       " 'clinics',\n",
       " 'BCI\\ntechnology',\n",
       " 'stroke rehabilitation',\n",
       " 'assessment',\n",
       " 'consciousness',\n",
       " 'current BCI systems',\n",
       " 'a level',\n",
       " 'success',\n",
       " 'they',\n",
       " 'changes',\n",
       " 'EEG signals',\n",
       " 'external stimuli',\n",
       " 'The P300 speller',\n",
       " 'paradigm',\n",
       " 'a notable example',\n",
       " 'a BCI design',\n",
       " 'external stimuli',\n",
       " 'a P300\\nspeller',\n",
       " 'the BCI user',\n",
       " 'a letter',\n",
       " 'they',\n",
       " 'a grid',\n",
       " 'letters',\n",
       " 'a computer monitor',\n",
       " 'The rows',\n",
       " 'columns',\n",
       " 'the grid',\n",
       " 'a random order',\n",
       " 'the letter',\n",
       " 'the user',\n",
       " ', a predictable waveform',\n",
       " 'an\\nEvent-Related Potential',\n",
       " 'ERP',\n",
       " 'the user’s EEG signals',\n",
       " 'ERPs',\n",
       " 'a single trial',\n",
       " 'multiple repetitions',\n",
       " 'flashing',\n",
       " 'the\\nrow',\n",
       " 'column',\n",
       " 'the letter',\n",
       " 'the user',\n",
       " 'BCI systems',\n",
       " 'ERPs',\n",
       " 'they',\n",
       " 'a number',\n",
       " 'disadvantages',\n",
       " 'usability',\n",
       " 'performance',\n",
       " 'instance',\n",
       " 'the use',\n",
       " 'external\\nstimuli',\n",
       " 'the user',\n",
       " 'ability',\n",
       " 'the task',\n",
       " 'hand',\n",
       " 'fatigue',\n",
       " 'prolonged use',\n",
       " 'some potential BCI users',\n",
       " 'an impaired ability',\n",
       " 'external stimuli',\n",
       " 'The communication rate',\n",
       " 'ERP-based paradigms',\n",
       " 'the rate',\n",
       " 'the stimuli',\n",
       " 'the time',\n",
       " 'the\\nprogression',\n",
       " 'the ERP',\n",
       " 'these types',\n",
       " 'BCI systems',\n",
       " 'a synchronous,\\ntime-locked fashion',\n",
       " 'some types',\n",
       " 'control tasks',\n",
       " 'example',\n",
       " 'a mouse cursor',\n",
       " 'an electric wheelchair',\n",
       " 'a robotic prosthesis',\n",
       " 'all instances',\n",
       " 'tasks',\n",
       " 'synchronous BCIs',\n",
       " 'Asynchronous BCI systems',\n",
       " 'time-locked external stimuli',\n",
       " 'BCIs',\n",
       " 'the Motor Imagery (MI) paradigm',\n",
       " 'two or more imagined\\nmotor movements',\n",
       " 'commands',\n",
       " 'the BCI system',\n",
       " '27–30',\n",
       " 'example',\n",
       " 'a\\nuser',\n",
       " 'their left hand',\n",
       " 'a mouse cursor',\n",
       " 'the left',\n",
       " 'their right hand',\n",
       " 'the cursor',\n",
       " 'the right',\n",
       " 'These types',\n",
       " 'BCIs',\n",
       " 'characteristic patterns',\n",
       " 'EEG signals',\n",
       " 'motor movements',\n",
       " 'the movements',\n",
       " 'These patterns',\n",
       " 'the form',\n",
       " 'an increase',\n",
       " 'decrease',\n",
       " 'amplitude',\n",
       " 'µ and β rhythms',\n",
       " 'frequencies',\n",
       " 'the centro-parietal regions',\n",
       " 'the hemisphere',\n",
       " 'the\\nbrain',\n",
       " 'the motor movement',\n",
       " 'it',\n",
       " 'some\\npeople',\n",
       " 'motor impairments',\n",
       " 'MI-based BCIs',\n",
       " 'these systems',\n",
       " 'low communication rates',\n",
       " 'extensive training',\n",
       " 'the fact',\n",
       " 'these systems',\n",
       " 'lateralized changes',\n",
       " 'the EEG signals',\n",
       " 'similar frequency ranges',\n",
       " 'relatively small regions',\n",
       " 'the cortex',\n",
       " 'it',\n",
       " 'more than a few imagined motor movements',\n",
       " 'The Mental Task (MT) paradigm',\n",
       " 'an approach',\n",
       " 'MI',\n",
       " 'various\\nother cognitive tasks',\n",
       " 'instance',\n",
       " 'a user',\n",
       " 'a song',\n",
       " 'a mouse',\n",
       " 'the cursor',\n",
       " 'their left arm',\n",
       " 'the cursor',\n",
       " 'their right arm',\n",
       " 'it',\n",
       " 'the right',\n",
       " 'time',\n",
       " 'practice',\n",
       " 'feedback',\n",
       " 'it',\n",
       " 'these tasks',\n",
       " 'The MT paradigm',\n",
       " 'a number',\n",
       " 'research projects',\n",
       " 'cognitive psychology',\n",
       " 'various changes',\n",
       " 'the power spectra',\n",
       " 'EEG signals',\n",
       " 'a user',\n",
       " 'different mental tasks',\n",
       " 'the MI paradigm',\n",
       " 'the MT paradigm',\n",
       " 'self-paced\\nand stimulus-free control',\n",
       " 'MT-based approaches',\n",
       " 'many distinct mental states',\n",
       " 'the mental tasks',\n",
       " 'a way',\n",
       " 'a variety',\n",
       " 'responses',\n",
       " 'different regions',\n",
       " 'the brain',\n",
       " 'other words',\n",
       " 'the wide variety',\n",
       " 'patterns',\n",
       " 'different mental tasks',\n",
       " 'more\\ndegrees',\n",
       " 'control',\n",
       " 'it',\n",
       " 'tasks',\n",
       " 'imagined motor movements',\n",
       " 'people',\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[noun_chunk.text for noun_chunk in doc.noun_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence tokenization\n",
    "\n",
    "Sentences are also extracted and, again, are represented as `Span`'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and I would like to\\nthank you all.',\n",
       " 'I would also like to thank my dissertation committee and all of the members of\\nthe BCI laboratory.',\n",
       " 'Bill Gavin, Patti Davies and Marla Roll, in particular, have taught me much\\nof what I know about EEG and how to work with participants in a kind and professional way.\\n',\n",
       " 'Brittany Taylor, Jewel Crasta, Stephanie Scott, Katie Bruegger, Kim Teh and Stephanie Teh have\\nall been especially instrumental in the success of my research and the BCI project and have all\\nbeen great sources of support and friendship.',\n",
       " 'Tomojit Ghosh and Fereydoon Vafaei have been\\ngreat friends and colleagues and were extremely helpful throughout the process of formulating\\nmy ideas and designing my experiments.',\n",
       " 'I would also like to extend a special thank you to\\neveryone that participated in our studies and, especially, to those who have graciously allowed\\nus to enter their homes.',\n",
       " 'I truly hope that this research helps to develop next-generation\\nassistive technologies for everyone who can benefit from them.',\n",
       " 'This work was supported in\\npart by the National Science Foundation through grant number 1065513 and through\\ngenerous support from the Department of Computer Science, Department of Occupational\\nTherapy and Department of Human Development and Family Studies at Colorado State\\nUniversity.',\n",
       " 'I have also received generous financial support from the Forney Family Scholarship\\nand through the Computer Science Department’s Artificial Intelligence and Evolutionary\\n',\n",
       " 'Computation Fellowship.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sent.text for sent in doc.sents][50:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By iterating over the tokens contained in each span, we can easily get a nested list of tokens by sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['and', 'I', 'would', 'like', 'to', '\\n', 'thank', 'you', 'all', '.'],\n",
       " ['I',\n",
       "  'would',\n",
       "  'also',\n",
       "  'like',\n",
       "  'to',\n",
       "  'thank',\n",
       "  'my',\n",
       "  'dissertation',\n",
       "  'committee',\n",
       "  'and',\n",
       "  'all',\n",
       "  'of',\n",
       "  'the',\n",
       "  'members',\n",
       "  'of',\n",
       "  '\\n',\n",
       "  'the',\n",
       "  'BCI',\n",
       "  'laboratory',\n",
       "  '.'],\n",
       " ['Bill',\n",
       "  'Gavin',\n",
       "  ',',\n",
       "  'Patti',\n",
       "  'Davies',\n",
       "  'and',\n",
       "  'Marla',\n",
       "  'Roll',\n",
       "  ',',\n",
       "  'in',\n",
       "  'particular',\n",
       "  ',',\n",
       "  'have',\n",
       "  'taught',\n",
       "  'me',\n",
       "  'much',\n",
       "  '\\n',\n",
       "  'of',\n",
       "  'what',\n",
       "  'I',\n",
       "  'know',\n",
       "  'about',\n",
       "  'EEG',\n",
       "  'and',\n",
       "  'how',\n",
       "  'to',\n",
       "  'work',\n",
       "  'with',\n",
       "  'participants',\n",
       "  'in',\n",
       "  'a',\n",
       "  'kind',\n",
       "  'and',\n",
       "  'professional',\n",
       "  'way',\n",
       "  '.',\n",
       "  '\\n'],\n",
       " ['Brittany',\n",
       "  'Taylor',\n",
       "  ',',\n",
       "  'Jewel',\n",
       "  'Crasta',\n",
       "  ',',\n",
       "  'Stephanie',\n",
       "  'Scott',\n",
       "  ',',\n",
       "  'Katie',\n",
       "  'Bruegger',\n",
       "  ',',\n",
       "  'Kim',\n",
       "  'Teh',\n",
       "  'and',\n",
       "  'Stephanie',\n",
       "  'Teh',\n",
       "  'have',\n",
       "  '\\n',\n",
       "  'all',\n",
       "  'been',\n",
       "  'especially',\n",
       "  'instrumental',\n",
       "  'in',\n",
       "  'the',\n",
       "  'success',\n",
       "  'of',\n",
       "  'my',\n",
       "  'research',\n",
       "  'and',\n",
       "  'the',\n",
       "  'BCI',\n",
       "  'project',\n",
       "  'and',\n",
       "  'have',\n",
       "  'all',\n",
       "  '\\n',\n",
       "  'been',\n",
       "  'great',\n",
       "  'sources',\n",
       "  'of',\n",
       "  'support',\n",
       "  'and',\n",
       "  'friendship',\n",
       "  '.'],\n",
       " ['Tomojit',\n",
       "  'Ghosh',\n",
       "  'and',\n",
       "  'Fereydoon',\n",
       "  'Vafaei',\n",
       "  'have',\n",
       "  'been',\n",
       "  '\\n',\n",
       "  'great',\n",
       "  'friends',\n",
       "  'and',\n",
       "  'colleagues',\n",
       "  'and',\n",
       "  'were',\n",
       "  'extremely',\n",
       "  'helpful',\n",
       "  'throughout',\n",
       "  'the',\n",
       "  'process',\n",
       "  'of',\n",
       "  'formulating',\n",
       "  '\\n',\n",
       "  'my',\n",
       "  'ideas',\n",
       "  'and',\n",
       "  'designing',\n",
       "  'my',\n",
       "  'experiments',\n",
       "  '.'],\n",
       " ['I',\n",
       "  'would',\n",
       "  'also',\n",
       "  'like',\n",
       "  'to',\n",
       "  'extend',\n",
       "  'a',\n",
       "  'special',\n",
       "  'thank',\n",
       "  'you',\n",
       "  'to',\n",
       "  '\\n',\n",
       "  'everyone',\n",
       "  'that',\n",
       "  'participated',\n",
       "  'in',\n",
       "  'our',\n",
       "  'studies',\n",
       "  'and',\n",
       "  ',',\n",
       "  'especially',\n",
       "  ',',\n",
       "  'to',\n",
       "  'those',\n",
       "  'who',\n",
       "  'have',\n",
       "  'graciously',\n",
       "  'allowed',\n",
       "  '\\n',\n",
       "  'us',\n",
       "  'to',\n",
       "  'enter',\n",
       "  'their',\n",
       "  'homes',\n",
       "  '.'],\n",
       " ['I',\n",
       "  'truly',\n",
       "  'hope',\n",
       "  'that',\n",
       "  'this',\n",
       "  'research',\n",
       "  'helps',\n",
       "  'to',\n",
       "  'develop',\n",
       "  'next',\n",
       "  '-',\n",
       "  'generation',\n",
       "  '\\n',\n",
       "  'assistive',\n",
       "  'technologies',\n",
       "  'for',\n",
       "  'everyone',\n",
       "  'who',\n",
       "  'can',\n",
       "  'benefit',\n",
       "  'from',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['This',\n",
       "  'work',\n",
       "  'was',\n",
       "  'supported',\n",
       "  'in',\n",
       "  '\\n',\n",
       "  'part',\n",
       "  'by',\n",
       "  'the',\n",
       "  'National',\n",
       "  'Science',\n",
       "  'Foundation',\n",
       "  'through',\n",
       "  'grant',\n",
       "  'number',\n",
       "  '1065513',\n",
       "  'and',\n",
       "  'through',\n",
       "  '\\n',\n",
       "  'generous',\n",
       "  'support',\n",
       "  'from',\n",
       "  'the',\n",
       "  'Department',\n",
       "  'of',\n",
       "  'Computer',\n",
       "  'Science',\n",
       "  ',',\n",
       "  'Department',\n",
       "  'of',\n",
       "  'Occupational',\n",
       "  '\\n',\n",
       "  'Therapy',\n",
       "  'and',\n",
       "  'Department',\n",
       "  'of',\n",
       "  'Human',\n",
       "  'Development',\n",
       "  'and',\n",
       "  'Family',\n",
       "  'Studies',\n",
       "  'at',\n",
       "  'Colorado',\n",
       "  'State',\n",
       "  '\\n',\n",
       "  'University',\n",
       "  '.'],\n",
       " ['I',\n",
       "  'have',\n",
       "  'also',\n",
       "  'received',\n",
       "  'generous',\n",
       "  'financial',\n",
       "  'support',\n",
       "  'from',\n",
       "  'the',\n",
       "  'Forney',\n",
       "  'Family',\n",
       "  'Scholarship',\n",
       "  '\\n',\n",
       "  'and',\n",
       "  'through',\n",
       "  'the',\n",
       "  'Computer',\n",
       "  'Science',\n",
       "  'Department',\n",
       "  '’s',\n",
       "  'Artificial',\n",
       "  'Intelligence',\n",
       "  'and',\n",
       "  'Evolutionary',\n",
       "  '\\n'],\n",
       " ['Computation', 'Fellowship', '.']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[token.text for token in sent] for sent in list(doc.sents)[50:60]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis\n",
    "\n",
    "Sentiment analysis is contained in some spaCy models, but, unfortunately not the `en_core_web_sm` model.  If it were, however, the sentiment score for the document would be stored in the floating point `.sentiment` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, spaCy seems pretty easy to get started with.  I do wonder a bit if the `Span` data model abstraction, i.e., iterables of tokens, is really sufficient for a wide variety of NLP tasks, but I'll have to ponder on that a bit.  In future notebooks, I hope to explore performance a bit more and also sentiment and training of custom models.  Perhaps I can also think of an easy practical NLP application to integrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
